var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "Hi! Welcome to the DataGator Website! Are you stuck on a project where you have to use and analyze data? If you need help getting started using computational tools and methods such as Machine Learning, statistical models, visualization techniques or similar? Do you just need to brainstorm some ideas about your project in analysis?\nThen drop by the Campus Center of Library for help on your project. Check the calendar see when the tables are open and to make an appointment!\nThe illustrious DataGators will help you get started with your computational project. When you go to their table, be sure to bring your computer and your idea to start the discussion.\nOpen to all students and faculty. Organized and supported by the Department of Computer and Information Science and the Office of the Associate Provost for Institutional Effectiveness, Strategic Planning, and Assessment.",
    "description": "Welcome",
    "tags": [],
    "title": "DataGators",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "‚Äã Welcome Statement Hi! Welcome to research!\nOf research, a wise person once wrote that, one never completes a research project in isolation of others. This bright quote signifies that finding and correctly harnessing appropriate resources for research is what makes for a successful conclusion.\nResearch is a systematic process of investigating a specific topic or question to gather information, analyze data, and reach conclusions. It involves forming hypotheses, collecting data, analyzing it, and sharing findings.\nThe Role of Resources in Research\nTo conduct research effectively, you need access to various resources that support your investigations. These resources provide the foundation for your work, helping you:\nAccess existing knowledge: Books, journal articles, databases, and websites offer a wealth of information on a particular topic. Methodology and framework: Resources guide you on how to approach research, including best practices, data collection methods, and analytical techniques. Data and evidence: Primary and secondary data are essential for supporting or challenging hypotheses. Tools for analysis: Software, surveys, lab equipment, and online tools help you interpret complex information accurately and efficiently. Collaboration and networking: Interacting with other researchers or joining academic communities can facilitate knowledge sharing and new inquiry directions. Keeping Track of Resources\nAs you work on your research project, keep a note of the resources you use. This helps in several ways:\nOrganization: You‚Äôll have a centralized repository for your notes, calculations, datasets, and code. Reusability: You can revisit these elements for future projects or reuse code from one project to another. Citation: Properly documenting your resources enables you to cite them accurately, making your work reproducible by others. Resources That We Use\nOn this page, we‚Äôve curated some of the resources we use in our research. These include texts, tutorials, and other handy elements that have contributed to our projects‚Äô success. We hope you find these resources helpful for your own research endeavors! More resources will be added ad they are discovered. If you you find something noteworthy, please let us know!",
    "description": "‚Äã Welcome Statement Hi! Welcome to research!\nOf research, a wise person once wrote that, one never completes a research project in isolation of others. This bright quote signifies that finding and correctly harnessing appropriate resources for research is what makes for a successful conclusion.\nResearch is a systematic process of investigating a specific topic or question to gather information, analyze data, and reach conclusions. It involves forming hypotheses, collecting data, analyzing it, and sharing findings.",
    "tags": [],
    "title": "Resources",
    "uri": "/resources/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Resources",
    "content": "Welcome to a resources page for Bioinformatics research. Here you will find a list of links for data, tools, tutorials and related resources that may be very helpful to your work.\nSoftware\nInstallations\nRStudio R Programming Language Python Programming Language Git for Mac Git for Windows Git for all platforms Python Programming Language Python for Biologists BioPython Online Tools\nsentiment viz Tweet Sentiment Visualization Online R programming Snippets ‚Äì Run any R code you line online JDoodle Python Programming Resources\nPlay with code from W3‚Äôs super Python Tutorial Write code locally using Jupyter Interactive Python. Think Python, a textbook, by Allen B. Downey Publisher Website The Python Programming Language Online\nOnline R programming Articles\nGetting started with Markdown Tutorials\nStatmethods R programming Tutorial by Datacamp Dealing with GenBank files in Biopython Allegheny College Department of Computer Science tutorials Coding Train‚Äôs Git and GitHub for Poets Setting Up Git on Linux Setting up Git Getting Started with Python in VS Code 11 Best VS Code extensions for Python (2022) ssh keys Luman‚Äôs ssh keys video tutorial Tools\nCOVID-19 Forecasts Virus Explorer TCoffee: http://tcoffee.crg.cat/apps/tcoffee/tutorial.html Hidden Markov Models (Youtube): https://www.youtube.com/watch?v=TPRoLreU9lA The Double Helix (Documentary about DNA discovery, 17 mins): https://media.hhmi.org/biointeractive/films/Double_Helix.html The Chemical Structure of DNA: https://www.biointeractive.org/classroom-resources/chemical-structure-dna The Structure of DNA: https://www.youtube.com/watch?v=o_-6JXLYS-k The definition to 5‚Äô end and 3‚Äô end of a DNA strand - Simple animated HD: https://www.youtube.com/watch?v=qWZYpHSXvJo What happens when your DNA is damaged?: https://www.youtube.com/watch?v=vP8-5Bhd2ag Mutations and Natural Selection: https://www.youtube.com/watch?v=BBI7GoIyoog Protein synthesis animation: https://www.youtube.com/watch?v=NDIJexTT9j0 The Lung Endothelial Cell Atlas http://www.lungendothelialcellatlas.com The COPD Cell Atlas http://www.copdcellatlas.com The COVID Cell Atlas: http://www.covidcellatlas.com Idiopathic Pulmonary Fibrosis Cell Atlas: http://www.ipfcellatlas.com/ Codon Usage Database: https://www.kazusa.or.jp/codon/ The Comprehensive Antibiotic Resistance Database: https://card.mcmaster.ca/ ermB anti resistance gene: https://card.mcmaster.ca/ontology/36514] SIM: Alignment tool for protein sequences: https://web.expasy.org/sim/ Blast analysis: https://card.mcmaster.ca/analyze Diamond; a Blast alternative: http://www.diamondsearch.org/index.php HMMER: biosequence analysis using profile hidden Markov models: http://hmmer.org/ Gene Ontology Resource: http://geneontology.org/ Panther Classification System: http://www.pantherdb.org/ Blast: https://blast.ncbi.nlm.nih.gov/Blast.cgi EGassembler: https://www.genome.jp/tools/egassembler/ ELM tool kit: http://elm.eu.org/ Protein Data Bank: http://www.rcsb.org/ Predict protein: https://open.predictprotein.org/ String: a protein database: https://string-db.org/ Database of protein domains, families and functional sites: https://prosite.expasy.org/ Needleman-Wunsch algorithm Interactive demo: http://experiments.mostafa.io/public/needleman-wunsch/ UGENE is free open-source cross-platform bioinformatics software: http://ugene.net/ The Cell Map: http://thecellmap.org/?q=pex6 The String Database For Analysis: http://string-db.org/ AmiGo: Gene products and gene annotations: http://amigo.geneontology.org/amigo/landing Genetics Home Reference: https://ghr.nlm.nih.gov/ Northeast Structural Genomics Consortium: http://nesg.org/galleries.html ModEval: An evaluation tool for protein structure models: https://modbase.compbio.ucsf.edu/modeval/ PyMol ‚Äì A user-sponcored molecular visualization system on an open-source foundation, maintained and distributed by Schrodinger: https://pymol.org/2/ Qiime2 ‚Äì is a next-generation microbiome bioinformatics platform that is extensible, free, open source, and community developed: https://qiime2.org/ DrugBank ‚Äì a pharmaceutical knowledge base that is enabling major advances across the data-driven medicine industry: https://go.drugbank.com/ Augustus [gene prediction] ‚Äì a software to predict genes in eukaryotic genomic sequences: http://bioinf.uni-greifswald.de/augustus/ Research and Data Resources An interactive visualization of the exponential spread of COVID-19: https://91-divoc.com/pages/covid-visualization/ Project Tycho: https://www.tycho.pitt.edu/ Cataracts and Genetics: https://knowyourdna.com/cataracts-and-genetics/ National Human Genome Research Institute: https://www.genome.gov/ Max Planck Institute For Molecular Genetics: https://www.molgen.mpg.de/2168/en Resources for Cerebral Palsy Cerebral Palsy Guidance: https://www.cerebralpalsyguidance.com/ Cerebral Palsy Associated Disorders: https://www.cerebralpalsyguidance.com/cerebral-palsy/associated-disorders/ Cerebral Palsy Guide: https://www.cerebralpalsyguide.com/cerebral-palsy/coexisting-conditions/cancer/ The Cerebral Palsy Toolkit: https://www.levinperconti.com/birth-injury/cerebral-palsy/guide-toolkit/ Causes: https://www.cerebralpalsyguidance.com/cerebral-palsy/causes/ Note If you find a good link for Bioinformatics research that you believe would fit nicely here, please let me know!\nobonhamcarter at allegheny dot edu",
    "description": "Welcome to a resources page for Bioinformatics research. Here you will find a list of links for data, tools, tutorials and related resources that may be very helpful to your work.\nSoftware\nInstallations\nRStudio R Programming Language Python Programming Language Git for Mac Git for Windows Git for all platforms Python Programming Language Python for Biologists BioPython Online Tools\nsentiment viz Tweet Sentiment Visualization Online R programming Snippets ‚Äì Run any R code you line online JDoodle Python Programming Resources",
    "tags": [],
    "title": "BioMedical and Bioinformatics Resources",
    "uri": "/resources/bioinformatics_resources/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Resources",
    "content": "üöÄ Welcome to a resources page for Data Science research. Here you will find a list of links for data, tools, tutorials and related resources that may be very helpful to your work. Note: If you find any resources that you think are important, please let me know [obonhamcarter(a)allegheny(dot)com]. üòÑ\n‚Äã Textbooks\nWickham, Hadley, and Garrett Grolemund. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data., O‚ÄôReilly Media, Inc., 2016.\nBook Website Latest version of the book Julia Silge And David Robinson. Text Mining With R: A Tidy Approach., O‚ÄôReilly Media, Inc., 2019.\nBook Website Think Python, first edition, by Allen B. Downey.\nPublisher Website Circular Visualization in R by Zuguang Gu\nBook Website An Introduction to Machine Learning with R by Laurent Gatto\nBook Website Software\nInstallations\nRStudio R Programming Language Python Programming Language Git for Mac Git for Windows Git for all platforms Online Tools\nDeepnote sentiment viz Tweet Sentiment Visualization Online R programming Snippets ‚Äì Run any R code you line online JDoodle Python Programming Resources\nPlay with code from W3‚Äôs super Python Tutorial Write code locally using Jupyter Interactive Python. Think Python, a textbook, by Allen B. Downey. Publisher Website The Python Programming Language Articles for Learning\nGetting started with Markdown Industrial Careers in the Age of Machine Learning Tutorials\nStatmethods R programming Tutorial by Datacamp Data Science Dojo Machine Learning in R for beginners (Interactiving coding!) Your First Machine Learning Project in R Step-By-Step Machine learning with the ‚Äúdiabetes‚Äù data set in R Intro to Machine Learning with R \u0026 caret Jupyter Notebooks Gallery ANOVA in R | A Complete Step-by-Step Guide with Examples The Paired t-Test An Introduction to t-Tests | Definitions, Formula and Examples Colors for Plotting in R Stat545: a reference for R and programming in Analytics Allegheny College Department of Computer Science tutorials Coding Train‚Äôs Git and GitHub for Poets Setting Up Git on Linux Setting up Git Getting Started with Python in VS Code 11 Best VS Code extensions for Python (2022) ssh keys Luman‚Äôs ssh keys video tutorial Machine Learning in R for beginners Providers of Data for projects\nawesome-public-datasets Finviz COVID-19 Forecasts An interactive visualization of the exponential spread of COVID-19 Project Tycho Pelletier Library at Allegheny College (online services) World Health Organization The World Bank Noncommunicable Disease Surveillance, Monitoring and Reporting (NCDS) Demographic and Health Surveys Harvest Choice Food and Agricultural Organization World Population Prospects Centres for Disease Control and Prevention (CDC) US Food and Drug Administration Home Page The US Census Institute for Health Metrics and Evaluation IBM‚Äôs collection of opensource data sets Google‚Äôs opensource data sets Data.world: data for business-based questions Kaggle ipums Kaggle‚Äôs Star Trek Scripts (Could be a cool idea!) Project Gutenberg: Free eBooks ‚Ä¶ And many others that you may conveniently find using online searches.",
    "description": "üöÄ Welcome to a resources page for Data Science research. Here you will find a list of links for data, tools, tutorials and related resources that may be very helpful to your work. Note: If you find any resources that you think are important, please let me know [obonhamcarter(a)allegheny(dot)com]. üòÑ\n‚Äã Textbooks\nWickham, Hadley, and Garrett Grolemund. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data., O‚ÄôReilly Media, Inc., 2016.",
    "tags": [],
    "title": "General Resources",
    "uri": "/resources/general/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Resources",
    "content": "‚Äã ‚Äã\nOpportunities for Women in Computing Below are some links from National Center for Women \u0026 Information Technology (NCWIT) which offers women support, encouragement and information to help women to gain experience in computing and to build meaningful careers in computing technology.\nThe National Center for Women \u0026 Information Technology (NCWIT) is the farthest-reaching network of change leaders focused on advancing innovation by correcting underrepresentation in computing.\nNCWIT\n‚Äã ‚Äã\nAspirations In Computing (AiC)\nWhy-Aspirations-Matters AiC Program Elements AspireIT: Computing Learning Experiences Join the AIC Community\nVolunteer With AIC\n‚Äã ‚Äã\nDid you know that AIC offers awards for amazing work in computing?\nNCWIT Collegiate Award\nRecipients in 2022\nFinalists in 2022",
    "description": "‚Äã ‚Äã\nOpportunities for Women in Computing Below are some links from National Center for Women \u0026 Information Technology (NCWIT) which offers women support, encouragement and information to help women to gain experience in computing and to build meaningful careers in computing technology.\nThe National Center for Women \u0026 Information Technology (NCWIT) is the farthest-reaching network of change leaders focused on advancing innovation by correcting underrepresentation in computing.",
    "tags": [],
    "title": "Women In Computing",
    "uri": "/resources/womenincomputing/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Resources",
    "content": "The Steps of Writing an Introduction Writing a thesis introduction is a crucial part of your overall thesis work. It sets the stage for your research and provides the reader with an overview of the key elements of your study. Here are the basic steps to help you write a compelling thesis introduction:\nStart with a Hook: Begin your introduction with a compelling hook or an engaging anecdote that captures the reader‚Äôs attention. This could be a relevant quote, a surprising fact, or a thought-provoking question.\nProvide Background Information: Give a brief overview of the general topic of your thesis. Provide enough context for readers to understand the broader subject area and the importance of your research within that context.\nState the Problem or Research Question: Clearly articulate the problem or research question that your thesis aims to address. This should be concise and specific, outlining the gap in knowledge that your research intends to fill.\nJustify the Research: Explain why your research is important and why it matters in the larger academic or practical context. Highlight the significance of addressing the identified problem or question.\nPresent the Objectives or Hypotheses: Outline the specific objectives of your research or, if applicable, state your hypotheses. This helps set the direction for your study and gives readers a clear understanding of what you aim to achieve.\nProvide an Overview of the Methodology: Briefly describe the research design and methodology you used in your study. This includes the research approach, data collection methods, and analysis techniques. This gives the reader an idea of how you conducted your research.\nHighlight the Contribution: Clearly state what contribution your research makes to the existing body of knowledge. Identify the gaps in the literature that your thesis addresses and emphasize how your work adds value to the field.\nOutline the Structure of the Thesis: Provide a roadmap for the reader by outlining the structure of your thesis. Mention how the subsequent chapters are organized and briefly describe what each chapter will cover.\nBe Concise and Clear: Keep your introduction concise and focused. Avoid unnecessary details and jargon. Clearly express your ideas in a way that is accessible to a broad audience.\nRevise and Refine: Once you‚Äôve drafted your introduction, revise and refine it. Ensure that each sentence serves a purpose and contributes to the overall coherence and flow of the introduction.\nRemember that the introduction is the first impression your thesis makes on the reader, so it‚Äôs essential to make it engaging and informative. Consider seeking feedback from peers or advisors to refine your introduction further.\nHow can I write better?! When completing any assignment in research or in your classes, the quality of your writing is very important. Below are some resources that may help in your writing.\nOnline Resources Online guide to writing: Maytum Center for Student Success;Writing and Speaking Consultants at Allegheny College‚Äôs Writing Center\nOnline guide to writing: Available from the University of Maryland",
    "description": "The Steps of Writing an Introduction Writing a thesis introduction is a crucial part of your overall thesis work. It sets the stage for your research and provides the reader with an overview of the key elements of your study. Here are the basic steps to help you write a compelling thesis introduction:\nStart with a Hook: Begin your introduction with a compelling hook or an engaging anecdote that captures the reader‚Äôs attention. This could be a relevant quote, a surprising fact, or a thought-provoking question.",
    "tags": [],
    "title": "Writing Resources",
    "uri": "/resources/writing/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "‚Äã Sherlock Holmes once said, Data! Data! Data! I can‚Äôt make bricks without clay. The DataGators maintain that this fact is quite true, however, if given the data, how would Sherlock actually build his bricks??\nThere is the same type trouble in data science research ‚Äì once you have the data, then what?!\nHow do you start the project from a spreadsheet of stuff?? How to make something amazing from a file filled with who-knows-what?! Come talk to the DataGators to get some ideas about how to work with your data. Before long, you will have your foundation ready for brick building!\nBook An Appointment Looking for help with your Data Science project and need some help getting started? Then come find the DataGators in the Campus Center or Library to get some assistance! Calendar\nHours and Locations Find the DataGators at the following places for the Spring 2025 Semester.\nDay Begin to End Location Monday 12:00pm to 2:00pm Campus Center; first floor Wednesday 3:00pm to 5:00pm Pelletier Library; tutorials area Thursday 9:00am to 2:00pm Pelletier Library; tutorials area Thursday 3:00pm to 5:00pm Pelletier Library; tutorials area Who Are the Gators? I once heard that the DataGators team turned down Nobel Prizes since there was no room left in their trophy cabinets for more stuff. Amazing! But who are these remarkable people that make up the DataGators team? How do they know data so well? Find out here about makes them so illustrious!\nQR Codes Are you browsing the DataGators website looking for souvenirs, or something absolutely amazing that you can take away with you for future reference??\nIf so, then take a Free QR code image!\nThere are two amazing QR codes to collect! One will lead you to the main DataGators website, and the other will get you to a page where you can set up an Earth Shattering appointment with DataGator to get help on your data science project.\nOn that note‚Ä¶\nWhy not take one on-the-house to print up and stick on your wall?! We have been told that QR codes are remarkably stylish in a modern-art sort of way!",
    "description": "Contacts",
    "tags": [],
    "title": "Contacts",
    "uri": "/contacts/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Contacts",
    "content": "Many times, you might be using your phone to make a quick appointment. These QR Codes will hopefully help you save time! The yellow QR Code takes you to the contacts page where you can make an appointment. The green QR Code takes you to the main page of this website so that you can take a look around. Cool, right?!\n‚Äã Book an appointment using your phone! http://www.data-gators.com/contacts/calendar/ ‚Äã Then use your phone to check out the rest of the site! https://data-gators.com/",
    "description": "Many times, you might be using your phone to make a quick appointment. These QR Codes will hopefully help you save time! The yellow QR Code takes you to the contacts page where you can make an appointment. The green QR Code takes you to the main page of this website so that you can take a look around. Cool, right?!\n‚Äã Book an appointment using your phone! http://www.data-gators.com/contacts/calendar/",
    "tags": [],
    "title": "QR Codes",
    "uri": "/contacts/qrcodes/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Contacts",
    "content": "Alish\nHello, my name is Alish. I am a software engineer and data scientist with experience in Python, C++, JavaScript, and R. I am passionate about helping others utilize technology to empower themselves and their communities. I enjoy developing applications that provide accessible resources, enabling people to learn, grow, and make informed decisions in an increasingly digital world.\nDaniel\nA goal oriented passionate software engineer who started from Addis Ababa, Ethiopia. driven to make an impact in every step and action I take. I like working with software and being challenged with logic or algorithmic problems. I am comfortable working with big data manipulations, data organization and visualization, and machine learning.\nKatie\nHi, I‚Äôm Katie. I‚Äôm a self-taught programmer with a strong interest in web development and data visualization. I am a senior Art, Science, and Innovation major with a German minor. My background includes experience in Python, HTML, CSS, and JavaScript. I focus on building intuitive and engaging applications. I‚Äôm passionate about exploring the intersection of technology and art, using programming to create unique and interactive experiences.\nLuke\nMy name is Luke and I am a senior at Allegheny College and I am a Computer Science major! The programming languages that I am most proficient in are Python and R. I have completed the course CMPSC 301 (Data Science) which equipped me with the knowledge to be able to be a member of the Datagators! I can assist you in data wrangling and data visualization along with assistance in how to use R and R studio to do so.\nOrion\nHi, I‚Äôm Orion. I‚Äôm a data scientist, and I‚Äôve got plenty of experience with data analysis. I work primarily with Python, R, Dart, and Java. I love data analytics, machine learning, and statistical analysis. I enjoy the rigor of breaking down datasets, ripping them apart to their bits and learning what makes them tick to create tools that aid proper decision making when consulting such data. I‚Äôm always looking for the next breakthrough to work on, whether it be working with data processing, or developing a machine learning model.\nOliver Bonham-Carter, Ph.D.\nemail: obonhamcarter(A)allegheny(dot)edu\nHi I am an Associate Professor at Allegheny College in the Department of Computer and Information Science (CIS). I am honored to be a part of this great team of thinkers! I teach Data Science, Database Systems and other courses where SQL, R programming and Python play central roles. Much of my research involves (you guessed it) data and computational, mathematical and statistical analysis. My recent work involved building an engin to connect parallel ideas from articles across the millions of scientific publications that are curated by National Center for Biotechnology Information and PubMed. Yummy!",
    "description": "Alish\nHello, my name is Alish. I am a software engineer and data scientist with experience in Python, C++, JavaScript, and R. I am passionate about helping others utilize technology to empower themselves and their communities. I enjoy developing applications that provide accessible resources, enabling people to learn, grow, and make informed decisions in an increasingly digital world.",
    "tags": [],
    "title": "The Team",
    "uri": "/contacts/gators/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Tutorials",
    "content": "‚Äã All sorts of tutorials to discoverer! üìñ Following technical tutorials is an excellent way to learn data science at your own pace. Here you will find tutorials and learning exercises to provide you with step-by-step guidance which will help to make complex concepts more accessible.\nüöÄ Did you know that you can code online? Click on the glasses to get started with Python and R Programming!\n‚ú® In each tutorial, the source code is available and the user is invited to copy and paste scripts into provided online Jupyter programming environment to run. While working with the code, please test it and then hack it by modifying it to behave differently to help you better understand how it works. Do not worry about ‚Äúbreaking the code‚Äù because if it does not work, just go back to the tutorial to copy and paste it again.\nüç∞ Click on the glasses under the menu to open the programming environment and get started in this amazing learning journey!\nTutorials in General Data Exploratoration",
    "description": "‚Äã All sorts of tutorials to discoverer! üìñ Following technical tutorials is an excellent way to learn data science at your own pace. Here you will find tutorials and learning exercises to provide you with step-by-step guidance which will help to make complex concepts more accessible.\nüöÄ Did you know that you can code online? Click on the glasses to get started with Python and R Programming!",
    "tags": [],
    "title": "About",
    "uri": "/tutorials/about/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Contacts",
    "content": "Book an Appointment! Appointments In the Library ‚Äã Making an appointment to meet with an DataGator is a wonderful way to be sure that your questions get answers.\nBut do not take our word for it, see what others in academia say about the benefits of making appointments to see tutors or instructors.\nGuaranteed Time Slot: By scheduling an appointment, students ensure that they have dedicated time with their instructor or tutor. This avoids the possibility of overlapping with other students‚Äô sessions and guarantees that the tutor will be available to meet with them.\nPersonalized Attention: With a scheduled appointment, students can expect more focused and personalized support. The instructor or tutor can prepare in advance for the specific topics the student needs help with, making the session more effective.\nBetter Time Management: When students book appointments, they can plan their study time more efficiently. Knowing exactly when they will meet with their instructor or tutor allows them to organize their schedule around these sessions, ensuring they stay on track.\nLess Waiting Time: Without an appointment, students may have to wait for an available tutor or instructor, especially if there are other students in need of help. An appointment guarantees they won‚Äôt be left waiting.",
    "description": "Book an Appointment! Appointments In the Library ‚Äã Making an appointment to meet with an DataGator is a wonderful way to be sure that your questions get answers.",
    "tags": [],
    "title": "Calendar",
    "uri": "/contacts/calendar/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Tutorials",
    "content": "Below are some simple tutorials to follow where you will learn general data exploration. What is data exploration, you ask?\n‚Äã Data exploration is the process of analyzing raw data to find patterns, characteristics, and relationships. It‚Äôs the first step in the data analysis process. Why is data exploration important?\nüéÜ It helps identify outliers, anomalies, and potential relationships üß® It helps form hypotheses and choose the right analysis methods üéà It helps prepare data for more processing and analysis ‚öΩ It helps make informed decisions and drive strategic initiatives",
    "description": "Below are some simple tutorials to follow where you will learn general data exploration. What is data exploration, you ask?\n‚Äã Data exploration is the process of analyzing raw data to find patterns, characteristics, and relationships. It‚Äôs the first step in the data analysis process. Why is data exploration important?",
    "tags": [],
    "title": "Exploratory Steps",
    "uri": "/tutorials/exploratory/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "‚Äã Hooray For Tutorials! Tutorials are self-taught lessons that one may use to improve learning, comprehension and over-all vision in a field. Here, you will find a series of fun and informational activities to help you explore and enjoy the depth of data science with computer programming. By the way, tutorials, in addition to other forms of self teachings, also help you to develop problem-solving skills, foster curiosity, and will provide you with a long-lasting foundation this ever-evolving field. You adventure in analytics and programming begin here!\nCheck back often to see new tutorials of hands-on practice, exciting activities and other amazing gems of learning that will benefit your learning in the amazing field of data science!\nOh Hey! I Nearly Forgot to Say!! Did you know that you can locally run the provided Python and R code for your activities on this site? You can copy, paste and hack the code using the Jupyter plug-in live site right here! You can also start up Jupyter‚Äôs live site by clicking on the icon under the menu on the left ‚ú® Neat, right?! üç∞\n‚Äã",
    "description": "‚Äã Hooray For Tutorials! Tutorials are self-taught lessons that one may use to improve learning, comprehension and over-all vision in a field. Here, you will find a series of fun and informational activities to help you explore and enjoy the depth of data science with computer programming. By the way, tutorials, in addition to other forms of self teachings, also help you to develop problem-solving skills, foster curiosity, and will provide you with a long-lasting foundation this ever-evolving field. You adventure in analytics and programming begin here!",
    "tags": [],
    "title": "Tutorials",
    "uri": "/tutorials/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Tutorials¬†\u003e¬†Exploratory Steps",
    "content": "Lesson: Introduction to R Programming and Data Science Overview In this lesson, we will introduce you to R programming by loading a synthetic dataset, performing basic correlations, and visualizing the data with several plots. After each code block, we‚Äôll explain how the code works step by step.\nPrerequisites Before we begin, make sure that you have R installed. You can download R from CRAN and use RStudio as an IDE to write and execute R code.\nStep 1: Loading a Synthetic Dataset First, we‚Äôll create a synthetic dataset that simulates a simple survey of people‚Äôs ages, heights, weights, and annual income. We will store this data in a data frame, which is a fundamental data structure in R.\n# Load the necessary library library(tibble) # Create a synthetic dataset set.seed(123) # Set a seed for reproducibility data \u003c- tibble( # Random ages between 20 and 60 Age = sample(20:60, 100, replace = TRUE), # Heights with a mean of 170 cm and SD of 10 Height = rnorm(100, mean = 170, sd = 10), # Weights with a mean of 70 kg and SD of 15 Weight = rnorm(100, mean = 70, sd = 15), # Income with a mean of 50,000 and SD of 15,000 Income = rnorm(100, mean = 50000, sd = 15000) ) # View the first few rows of the data head(data) Explanation: library(tibble): This loads the tibble package, which provides a modern version of data frames that are more user-friendly. set.seed(123): Ensures that the random numbers generated are the same every time you run the code. This makes your results reproducible. tibble(): Creates a tibble (data frame) with columns for Age, Height, Weight, and Income. rnorm(): Generates random numbers from a normal distribution. We use this for Height, Weight, and Income. head(data): Displays the first six rows of the dataset so we can inspect it. Step 2: Calculating Basic Correlations Now, let‚Äôs calculate the correlation between different columns (variables) in the dataset. Correlation tells us the strength and direction of the relationship between two variables.\n# Calculate correlations between numeric columns correlation_matrix \u003c- cor( data[, c( \"Age\", \"Height\", \"Weight\", \"Income\")]) # View the correlation matrix print(correlation_matrix) Explanation: cor(): This function computes the correlation matrix for the selected columns in the dataset. It ranges from -1 to 1, where: 1 indicates a perfect positive correlation. -1 indicates a perfect negative correlation. 0 indicates no correlation. data[, c(\"Age\", \"Height\", \"Weight\", \"Income\")]: This selects only the numeric columns from the dataset for the correlation computation. print(correlation_matrix): Displays the resulting correlation matrix. Step 3: Creating Plots to Visualize the Data Visualization is key in data science to explore relationships between variables. We will now generate a few plots.\n1. Scatter Plot: Age vs. Income # Load the ggplot2 library for data visualization library(ggplot2) # Create a scatter plot of Age vs. Income ggplot(data, aes( x = Age, y = Income)) + geom_point() + labs( title = \"Scatter Plot of Age vs. Income\", x = \"Age\", y = \"Income\") Explanation: library(ggplot2): Loads the ggplot2 package, which is a popular library for creating visualizations. ggplot(data, aes(x = Age, y = Income)): Initializes the plot with the data and sets the x and y axes to Age and Income, respectively. geom_point(): Adds points to the plot, creating a scatter plot. labs(): Adds a title and labels to the axes. 2. Histogram: Distribution of Height # Create a histogram of Height ggplot(data, aes(x = Height)) + geom_histogram( binwidth = 2, fill = \"blue\", color = \"black\", alpha = 0.7) + labs( title = \"Histogram of Height\", x = \"Height (cm)\", y = \"Frequency\") Explanation: geom_histogram(): Creates a histogram, which shows the frequency distribution of the Height variable. We define the bin width as 2. fill and color: Customize the color of the bars and their borders. alpha: Adjusts the transparency of the bars. 3. Boxplot: Weight Distribution by Age Group # Create a boxplot of Weight by Age Group data$AgeGroup \u003c- ifelse( data$Age \u003c 30, \"Under 30\", ifelse( data$Age \u003c= 40, \"30-40\", \"Over 40\")) ggplot( data, aes( x = AgeGroup, y = Weight, fill = AgeGroup) ) + geom_boxplot() + labs( title = \"Boxplot of Weight by Age Group\", x = \"Age Group\", y = \"Weight (kg)\") + theme_minimal() Explanation: ifelse(): Creates a new variable, AgeGroup, which categorizes the participants into three age groups: ‚ÄúUnder 30‚Äù, ‚Äú30-40‚Äù, and ‚ÄúOver 40‚Äù. geom_boxplot(): Creates a boxplot, which shows the distribution of Weight for each Age Group. theme_minimal(): Applies a clean minimal theme to the plot. Step 4: Summarizing the Results We have completed a few basic tasks:\nWe loaded a synthetic dataset and explored its structure. We calculated correlations between the numeric variables to understand their relationships. We created visualizations using ggplot2 to explore the data further. The following key observations could be made:\nIf the correlation between variables like Age and Income is strong, the scatter plot would show a clear trend. The histogram of Height helps us understand the distribution of people‚Äôs heights in the dataset. The boxplot allows us to see how Weight varies across different age groups. Conclusion In this lesson, you learned how to:\nLoad and explore a synthetic dataset. Perform basic correlation analysis to understand relationships between variables. Visualize data using scatter plots, histograms, and boxplots in R.",
    "description": "Lesson: Introduction to R Programming and Data Science Overview In this lesson, we will introduce you to R programming by loading a synthetic dataset, performing basic correlations, and visualizing the data with several plots. After each code block, we‚Äôll explain how the code works step by step.\nPrerequisites Before we begin, make sure that you have R installed. You can download R from CRAN and use RStudio as an IDE to write and execute R code.",
    "tags": [],
    "title": "Exploratory Steps With Synthetic Data",
    "uri": "/tutorials/exploratory/intro_synthetic/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Tutorials¬†\u003e¬†Exploratory Steps",
    "content": "Introduction to R Programming with the Penguin Dataset Let‚Äôs work with the penguins dataset, which contains data about three species of penguins in the Palmer Archipelago, Antarctica. The dataset includes measurements for:\nBill length (in mm) Bill depth (in mm) Flipper length (in mm) Body mass (in grams) Species (species of the penguin) We will perform basic exploratory data analysis (EDA) by calculating correlations and creating visualizations to better understand the relationships between these variables.\nStep 1: Install and Load the Required Libraries First, we‚Äôll need to install and load the palmerpenguins package, which contains the dataset.\n# Install the palmerpenguins package # (if not already installed) # install.packages(\"palmerpenguins\") # Load the required libraries library(palmerpenguins) library(ggplot2) Explanation:\ninstall.packages(\"palmerpenguins\") installs the palmerpenguins package, which contains the dataset. library(palmerpenguins) loads the package into the R environment. library(ggplot2) loads the ggplot2 package, which is used for creating advanced plots. Step 2: Load the Penguin Dataset We can now load the penguins dataset into R.\n# Load the penguins dataset data(\"penguins\") # Check the first few rows of the dataset head(penguins) Explanation:\ndata(\"penguins\") loads the dataset into memory. head(penguins) displays the first six rows of the dataset to give us an idea of its structure. Output:\nspecies island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g 1 Adelie Torgersen 39.1 18.7 181 3750 2 Adelie Torgersen 39.5 17.4 186 3800 3 Adelie Torgersen 40.3 18.0 195 3250 4 Adelie Torgersen 36.7 19.3 193 3450 5 Adelie Torgersen 39.3 20.6 190 3650 6 Adelie Torgersen 38.9 19.8 195 3625 Explanation:\nThe dataset contains several variables: species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, and body_mass_g. species is a factor representing the penguin species, while the other columns contain numeric data. Step 3: Calculate Correlations We can calculate the correlation matrix for the numeric variables (excluding species and island) to explore the relationships between the features.\n# Select numeric columns and calculate correlations numeric_data \u003c- penguins[, c( \"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\")] cor( numeric_data, use = \"complete.obs\") Explanation:\npenguins[, c(\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\")] selects only the numeric columns from the dataset. cor() computes the correlation matrix for these variables. use = \"complete.obs\" ensures that only complete observations (i.e., rows without missing values) are used for correlation calculation. Output:\nbill_length_mm bill_depth_mm flipper_length_mm body_mass_g bill_length_mm 1.000000 0.460317 0.871024 0.809872 bill_depth_mm 0.460317 1.000000 0.648209 0.650138 flipper_length_mm 0.871024 0.648209 1.000000 0.910144 body_mass_g 0.809872 0.650138 0.910144 1.000000 Explanation of Output:\nThe values in the correlation matrix indicate how strongly the variables are linearly related: For example, bill_length_mm and flipper_length_mm have a high positive correlation (0.87), meaning that as one increases, the other tends to increase as well. bill_depth_mm has a moderate correlation with body_mass_g (0.65), suggesting that as the depth of the bill increases, so does the body mass, but the relationship is not as strong. Step 4: Create Plots Scatter Plot: Bill Length vs Bill Depth We can create a scatter plot to visualize the relationship between bill length and bill depth.\n# Scatter plot of Bill Length vs Bill Depth ggplot( penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species) ) + geom_point() + labs( title = \"Bill Length vs Bill Depth\", x = \"Bill Length (mm)\", y = \"Bill Depth (mm)\") + theme_minimal() Explanation:\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) sets up the plot, with bill_length_mm on the x-axis, bill_depth_mm on the y-axis, and color-coded points based on species. geom_point() creates the scatter plot. labs() sets the title and axis labels. theme_minimal() applies a minimal theme to the plot for better visualization. Output: The plot will show how the bill length and depth vary by species, with different colors representing different species.\nBoxplot: Body Mass by Species Next, we create a boxplot to compare the distribution of body mass across species.\n# Boxplot of Body Mass by Species ggplot(penguins, aes( x = species, y = body_mass_g, fill = species)) + geom_boxplot() + labs( title = \"Body Mass Distribution by Species\", x = \"Species\", y = \"Body Mass (g)\" ) + theme_minimal() Explanation:\naes(x = species, y = body_mass_g, fill = species) specifies that the x-axis will represent species, the y-axis will represent body mass, and the boxes will be filled with colors based on species. geom_boxplot() creates the boxplot. labs() adds the title and axis labels. theme_minimal() applies a minimal theme. Output: This boxplot will display the distribution of body mass for each species, including the median, interquartile range, and outliers.\nPair Plot: Visualizing All Numeric Variables To explore the relationships between multiple numeric variables, we can create a pair plot.\n# Install and load GGally for # ggpairs if not already installed # install.packages(\"GGally\") library(GGally) # Create a pair plot of numeric variables ggpairs( penguins[, c( \"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\") ], aes(color = penguins$species)) Explanation:\nggpairs() from the GGally package creates a matrix of scatter plots, histograms, and correlation coefficients. aes(color = penguins$species) colors the points by species for easier differentiation. Output: This will generate a matrix of scatter plots for each pair of numeric variables, along with histograms for the individual variables, giving a comprehensive view of the relationships between the features.\nStep 5: Conclusion In this lesson, we:\nLoaded the penguins dataset. Calculated correlations between key numeric variables to identify relationships. Created several visualizations, including scatter plots, boxplots, and pair plots, to explore the dataset. These steps are essential for performing exploratory data analysis (EDA) in R, which helps you understand the structure of your data and identify important patterns.\nNext Steps: You can try experimenting with other plots, such as histograms or density plots, to explore the distribution of individual variables. Consider investigating missing data or exploring additional statistical analysis techniques, like hypothesis testing or regression analysis.",
    "description": "Introduction to R Programming with the Penguin Dataset Let‚Äôs work with the penguins dataset, which contains data about three species of penguins in the Palmer Archipelago, Antarctica. The dataset includes measurements for:\nBill length (in mm) Bill depth (in mm) Flipper length (in mm) Body mass (in grams) Species (species of the penguin) We will perform basic exploratory data analysis (EDA) by calculating correlations and creating visualizations to better understand the relationships between these variables.",
    "tags": [],
    "title": "Exploratory Steps with Penguins Data",
    "uri": "/tutorials/exploratory/intro_penguins/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Tutorials¬†\u003e¬†Exploratory Steps",
    "content": "Introduction to R Programming with the Iris Dataset Let‚Äôs work with the built-in iris dataset, which contains data on 150 different species of iris flowers. Each entry contains the following measurements for the flowers:\nSepal length Sepal width Petal length Petal width Species We will go through the steps of loading the dataset, calculating basic correlations, and creating visualizations to explore the relationships between the different features.\nStep 1: Load the Iris Dataset In R, you don‚Äôt need to load the iris dataset manually because it is built-in. We can directly access it.\n# Load the iris dataset data(iris) # Check the first few rows of the dataset head(iris) Explanation:\ndata(iris) loads the dataset into memory. head(iris) displays the first six rows of the iris dataset to give us an idea of its structure. Output:\nSepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa Step 2: Calculate Correlations We can calculate the correlation between numeric variables in the dataset to explore how they are related.\n# Calculate correlations between # numeric features (excluding the Species column) cor(iris[, 1:4]) Explanation:\niris[, 1:4] selects all rows and the first four columns (which contain the numeric data: sepal length, sepal width, petal length, and petal width). cor() computes the correlation matrix, which measures the linear relationships between pairs of variables. Output:\nSepal.Length Sepal.Width Petal.Length Petal.Width Sepal.Length 1.000000 -0.117570 0.871754 0.817941 Sepal.Width -0.117570 1.000000 -0.428440 -0.366125 Petal.Length 0.871754 -0.428440 1.000000 0.962865 Petal.Width 0.817941 -0.366125 0.962865 1.000000 Explanation of Output:\nThe correlation values range from -1 to 1, where:\n1 indicates a perfect positive correlation. -1 indicates a perfect negative correlation. 0 indicates no linear correlation. For example, Sepal Length and Petal Length have a high positive correlation (0.87), while Sepal Width and Petal Length have a moderate negative correlation (-0.43).\nStep 3: Create Basic Plots Scatter Plot: Sepal Length vs Petal Length We can plot Sepal Length against Petal Length to visualize their relationship.\n# Scatter plot of Sepal Length vs Petal Length plot(iris$Sepal.Length, iris$Petal.Length, main = \" Scatter Plot of Sepal Length vs Petal Length\", xlab = \"Sepal Length\", ylab = \"Petal Length\", pch = 19, col = iris$Species) Explanation:\nplot() is used to create a scatter plot. The pch = 19 argument sets the point type (solid circle), and col = iris$Species colors the points according to the flower species. main, xlab, and ylab set the title and axis labels for the plot. Output: This plot will show a scatter plot where each point represents a flower, and the color indicates the species.\nBoxplot: Sepal Length by Species A boxplot allows us to compare the distribution of sepal length across different species.\n# Boxplot of Sepal Length grouped by Species boxplot(Sepal.Length ~ Species, data = iris, main = \"Boxplot of Sepal Length by Species\", xlab = \"Species\", ylab = \"Sepal Length\", col = c( \"lightblue\", \"lightgreen\", \"lightcoral\") ) Explanation:\nSepal.Length ~ Species specifies that we want to plot Sepal Length for each species. boxplot() creates the boxplot, and the col argument specifies the colors for each species group. Output: This boxplot will display three boxes, one for each species, showing the range, median, and interquartile range of Sepal Length.\nPair Plot: Visualizing Relationships Between All Variables To explore the relationships between all the numeric variables simultaneously, we can use a pair plot (also known as a scatterplot matrix).\n# Install and load the GGally # package if not already installed # install.packages(\"GGally\") library(GGally) # Create a pair plot of the numeric variables ggpairs(iris[, 1:4], aes(color = iris$Species)) Explanation:\nThe ggpairs() function from the GGally package creates a matrix of scatter plots, showing the pairwise relationships between all numeric columns in the iris dataset. The aes(color = iris$Species) argument colors the points by species, making it easier to distinguish between the species in the plots. Output: This will generate a matrix of scatter plots, histograms, and correlations, making it easy to visually inspect the relationships between sepal length, sepal width, petal length, and petal width.\nStep 4: Conclusion In this lesson, we have:\nLoaded and explored the iris dataset. Calculated correlations between numeric variables. Created scatter plots, boxplots, and pair plots to visualize relationships between the features. This exercise helps in understanding both the basic analysis and visualization techniques in R, which are essential for data exploration in data science.\nNext Steps: You can try modifying the plots to explore other variables or try additional visualizations like histograms, density plots, or heatmaps. Experiment with different ggplot2 functions for more advanced visualizations.",
    "description": "Introduction to R Programming with the Iris Dataset Let‚Äôs work with the built-in iris dataset, which contains data on 150 different species of iris flowers. Each entry contains the following measurements for the flowers:\nSepal length Sepal width Petal length Petal width Species We will go through the steps of loading the dataset, calculating basic correlations, and creating visualizations to explore the relationships between the different features.\nStep 1: Load the Iris Dataset In R, you don‚Äôt need to load the iris dataset manually because it is built-in. We can directly access it.",
    "tags": [],
    "title": "Exploratory Steps With Iris Data",
    "uri": "/tutorials/exploratory/intro_iris/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Tutorials¬†\u003e¬†Exploratory Steps",
    "content": "Let‚Äôs explore the mpg dataset from the ggplot2 package in R. This lesson will cover how to load the dataset, calculate basic correlations, and create various plots, with detailed explanations for each step.\nIntroduction to R Programming with the MPG Dataset In this lesson, we will work with the mpg dataset, which is included in the ggplot2 package. The dataset contains information about the fuel efficiency (miles per gallon) of various car models, with additional details about each car such as:\nmpg: Miles per gallon (fuel efficiency). cyl: Number of cylinders in the car engine. disp: Displacement (engine size in cubic inches). hp: Horsepower. drat: Rear axle ratio. wt: Weight of the car (in 1000 pounds). qsec: Quarter mile time. vs: Engine type (0 = V-shaped, 1 = straight). am: Transmission type (0 = automatic, 1 = manual). gear: Number of forward gears. carb: Number of carburetors. We will load the dataset, explore basic correlations, and visualize the data using plots.\nStep 1: Install and Load Required Libraries To work with the mpg dataset, we first need to install and load the ggplot2 package. If it‚Äôs already installed, we can simply load it.\n# Install ggplot2 package if not already installed # install.packages(\"ggplot2\") # Load the ggplot2 package library(ggplot2) Explanation:\ninstall.packages(\"ggplot2\") installs the ggplot2 package (if it hasn‚Äôt been installed yet). ggplot2 is a popular package for creating data visualizations in R. library(ggplot2) loads the package into R, so we can access its built-in datasets and plotting functions. Step 2: Load the MPG Dataset The mpg dataset is included in ggplot2 by default, so we can load it without any extra steps.\n# Load the mpg dataset data(\"mpg\") # Check the first few rows of the dataset head(mpg) Explanation:\ndata(\"mpg\") loads the mpg dataset into memory. head(mpg) shows the first six rows of the dataset, so we can inspect the structure of the data. Output:\nmanufacturer model displ year cyl trans drv cty hwy fl 1 audi a4 1.8 1999 4 auto f 18 29 2 2 audi a4 1.8 1999 4 auto f 21 29 2 3 audi a4 2.0 1999 4 auto f 21 29 2 4 audi a4 2.0 1999 4 auto f 19 27 2 5 audi a4 2.8 1999 6 auto f 16 26 3 6 audi a4 2.8 1999 6 auto f 18 26 3 Explanation:\nThe dataset has columns for the manufacturer, model, engine displacement (displ), number of cylinders (cyl), transmission type (trans), drive type (drv), city and highway fuel efficiency (cty, hwy), and a factor variable fl. Step 3: Calculate Correlations We can calculate the correlation between numeric variables such as displ (engine displacement), cty (city mileage), and hwy (highway mileage).\n# Calculate correlations # between numeric variables (displ, cty, hwy) cor(mpg[, c(\"displ\", \"cty\", \"hwy\")]) Explanation:\nmpg[, c(\"displ\", \"cty\", \"hwy\")] selects the numeric columns displ, cty, and hwy from the dataset. cor() calculates the correlation matrix, which shows the strength and direction of the linear relationships between these variables. Output:\ndispl cty hwy displ 1.0000000 -0.897358 -0.779753 cty -0.897358 1.000000 0.918382 hwy -0.779753 0.918382 1.000000 Explanation of Output:\ndispl and cty have a strong negative correlation of -0.90, meaning that as the engine displacement increases, the city mileage tends to decrease. cty and hwy have a strong positive correlation of 0.92, meaning that cars with higher city mileage tend to also have higher highway mileage. displ and hwy have a moderate negative correlation of -0.78, showing that larger engines tend to have lower highway mileage. Step 4: Create Visualizations Scatter Plot: Engine Displacement vs Highway Mileage A scatter plot is a great way to visualize the relationship between two continuous variables. Let‚Äôs plot displ (engine displacement) against hwy (highway mileage).\n# Scatter plot of Displacement vs Highway Mileage ggplot(mpg, aes(x = displ, y = hwy)) + # Color points by car class geom_point(aes(color = class)) + labs( title = \"Engine Displacement vs Highway Mileage\", x = \"Engine Displacement (L)\", y = \"Highway Mileage (mpg)\") + theme_minimal() Explanation:\nggplot(mpg, aes(x = displ, y = hwy)) sets up the plot with displ on the x-axis and hwy on the y-axis. geom_point(aes(color = class)) creates a scatter plot where each point is colored by the class variable (the car‚Äôs class). labs() adds a title and axis labels. theme_minimal() applies a minimal theme for a cleaner plot. Output: This plot will display a scatter plot of engine displacement versus highway mileage, with points colored by car class.\nBoxplot: Highway Mileage by Cylinder Count A boxplot is useful for comparing the distribution of a numeric variable across different categories. We can use it to compare hwy (highway mileage) across different values of cyl (number of cylinders).\n# Boxplot of Highway Mileage by Number of Cylinders ggplot(mpg, aes(x = factor(cyl), y = hwy, fill = factor(cyl))) + geom_boxplot() + labs(title = \"Highway Mileage by Number of Cylinders\", x = \"Number of Cylinders\", y = \"Highway Mileage (mpg)\") + theme_minimal() Explanation:\naes(x = factor(cyl), y = hwy, fill = factor(cyl)) specifies that we want to plot hwy (highway mileage) for each category of cyl (number of cylinders). The factor(cyl) ensures that cyl is treated as a categorical variable. geom_boxplot() creates the boxplot, which shows the distribution of hwy for each cylinder category. labs() adds the title and axis labels. theme_minimal() ensures a clean, simple plot design. Output: The boxplot will display how highway mileage varies across different cylinder categories, showing the median, interquartile range, and potential outliers.\nHistogram: Distribution of City Mileage We can create a histogram to visualize the distribution of cty (city mileage).\n# Histogram of City Mileage ggplot(mpg, aes(x = cty)) + geom_histogram(binwidth = 1, fill = \"skyblue\", color = \"black\") + labs(title = \"Distribution of City Mileage\", x = \"City Mileage (mpg)\", y = \"Frequency\") + theme_minimal() Explanation:\naes(x = cty) specifies that we want to plot the distribution of cty (city mileage). geom_histogram() creates the histogram. binwidth = 1 controls the width of the bins, and fill = \"skyblue\" sets the color of the bars. labs() adds a title and axis labels. theme_minimal() applies a minimalistic theme for the plot. Output: This histogram will display how city mileage is distributed in the dataset, showing the frequency of different mileage values.\nStep 5: Conclusion In this lesson, we have:\nLoaded the mpg dataset from the ggplot2 package. Calculated correlations between key numeric variables like displ, cty, and hwy. Created scatter plots, boxplots, and histograms to explore the relationships and distributions of the data. These techniques are\nfundamental for performing exploratory data analysis (EDA) in R, which is crucial for understanding your data before moving on to more complex analyses.\nNext Steps: You can explore other visualizations such as density plots or bar charts. You may want to try building models to predict variables like mpg using linear regression or machine learning techniques.",
    "description": "Let‚Äôs explore the mpg dataset from the ggplot2 package in R. This lesson will cover how to load the dataset, calculate basic correlations, and create various plots, with detailed explanations for each step.\nIntroduction to R Programming with the MPG Dataset In this lesson, we will work with the mpg dataset, which is included in the ggplot2 package. The dataset contains information about the fuel efficiency (miles per gallon) of various car models, with additional details about each car such as:",
    "tags": [],
    "title": "Exploratory Steps With MPG Data",
    "uri": "/tutorials/exploratory/intro_mpg/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "You‚Äôll add here a general introduction of your calendar, events and etc.",
    "description": "Learner Section",
    "tags": [],
    "title": "Learner",
    "uri": "/learner/index.html"
  },
  {
    "breadcrumb": "DataGators¬†\u003e¬†Learner",
    "content": "üì¢ Need Help with Computational Analysis for Your Research? üì¢\nStudents and faculty at Allegheny College! Whether you‚Äôre working on data analysis, programming in R or Python, or need assistance with statistical methods and models, our Help Desks are here for you!\nWe offer assistance with:\nR and Python programming Preparing and cleaning data Performing statistical analyses Building models and visualizing data with plots And much more to support your research projects! Where to find us:\nCampus Center Help Desk Library Help Desk Our desks are staffed by fellow students, eager to help you tackle your computational analysis challenges. Stop by and get the support you need to succeed in your research!\nLet us help you bring your data to life! ‚ú®",
    "description": "This is the description of our sample project",
    "tags": [],
    "title": "We Do Data",
    "uri": "/learner/we_do_data/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "‚Äã Hey Researchers in Data at Allegheny College! If you are a student or faculty at Allegheny College and you need some help with your analysis, then we can help you set-up your analysis in your project.\nAs members of the Department of Computer and Information Science at Allegheny College, we often complete computational work and analyses for classes, senior thesis projects, and for other areas. We understand that there are many complex and often frustrating steps in computation that must be handled before the larger steps of the analytical project can be started. Our service is here to assist students and faculty with the technical aspects of their research, providing support to get you started and guiding you through the process.\nWhile we do not complete your work for you, nor do we promise to complete all your project‚Äôs computer code, we can meet with you to brainstorm solutions to overcome the computational challenges of your project in analysis. Our help desk is made up of talented students in computing who can offer solutions for completing the following types of tasks.\n‚Äã Coding and debugging: The creation of parts of code that will be used to complete some computatioan task. Data Wrangling: The process of cleaning, organizing, and transforming raw data into a usable format for analysis. Programming Support: Whether you‚Äôre working in Python, R, or another language, our students can assist in writing and debugging code to fit your research needs. Statistical Modeling: Design and implementation of statistical models to analyze data effectively and draw meaningful conclusions. Visualization: Creation of informative plots and graphs that help illustrate the findings of your research. And More: Got a question about the a computational step in a project? Then stop by one of our help desks and ask! Our goal is to enhance your research by providing the technical support necessary to navigate the computational aspects of your project. Whether you‚Äôre unsure how to get started with data analysis or need guidance with more advanced tasks, we‚Äôre here to help you succeed in your project of computational analysis.\n‚Äã üòÑ The DataGators project was put together by Associate Professor Oliver Bonham-Carter, in effort to enrich pedagogy in Data Science at Allegheny College.",
    "description": "About The DataGators",
    "tags": [],
    "title": "About Us",
    "uri": "/about/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "",
    "description": "",
    "tags": [],
    "title": "designs",
    "uri": "/designs/index.html"
  },
  {
    "breadcrumb": "DataGators",
    "content": "",
    "description": "",
    "tags": [],
    "title": "techs",
    "uri": "/techs/index.html"
  }
]
